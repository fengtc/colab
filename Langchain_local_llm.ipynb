{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fengtc/colab/blob/master/Langchain_local_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cECrSfVoZLl"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install docsearch\n",
        "!pip install tiktoken\n",
        "!pip install texts\n",
        "#!pip install faiss-gpu\n",
        "!pip install chromadb==0.3.26\n",
        "!pip install gradio\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGF2pCgSjxK9",
        "outputId": "05523057-5c9b-4184-bf86-98abe943bce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from gradio import gradio as gr\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 定义向量数据库存储路径\n",
        "vector_store_path = \"/content/drive/MyDrive/chroma\"\n",
        "\n",
        "# 初始化向量化模型\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "doc_search = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)\n",
        "\n",
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SY6TJpvU2g9"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "docsearch = FAISS.from_texts(texts, embeddings)\n",
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBpwpgsMSpd5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def chatbot(query):\n",
        "    if query.lower() == \"exit\":\n",
        "        return \"Goodbye!\"\n",
        "\n",
        "    docs = doc_search.similarity_search(query, k=3)\n",
        "    print(docs)\n",
        "    response = chain.run(input_documents=docs, question=query)\n",
        "    return response\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot,\n",
        "    inputs=gr.inputs.Textbox(label=\"请输入您的提问:\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"知识库\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "iface.launch(share=True,debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xDi37DsfOaG"
      },
      "outputs": [],
      "source": [
        "!pip install translate\n",
        "from translate import Translator\n",
        "\n",
        "# 创建翻译器对象\n",
        "translator = Translator(to_lang=\"zh\")\n",
        "\n",
        "# 打开 txt 文件\n",
        "with open('output.txt', 'r', encoding='utf-8') as f:\n",
        "    # 构造要翻译的文本\n",
        "    text = f.read()\n",
        "\n",
        "    # 翻译文本\n",
        "    translated_text = translator.translate(text)\n",
        "\n",
        "    # 写入新文本\n",
        "    with open('output_zh.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(translated_text)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1SKzg0vkSy_GioH8aN9SG6Li0RCin-rZY",
      "authorship_tag": "ABX9TyNmajqnOkdHMD8QeQQoO4U7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}